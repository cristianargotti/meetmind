# ğŸ§  MeetMind

> The most powerful meeting AI tool â€” on-device transcription, real-time AI insights, proactive participation as "Digital Cris".

## Architecture

```
ğŸ“± Flutter App (Dart) â”€â”€â–º dart:ffi â”€â”€â–º whisper.cpp â”€â”€â–º Whisper Base (on-device STT)
       â”‚                                    â””â”€â”€â–º CoreML/Metal (iOS) + NNAPI (Android)
       â”‚
       â””â”€â”€â–º WebSocket â”€â”€â–º â˜ï¸ FastAPI Backend (Python)
                                  â”‚
                                  â”œâ”€â”€â–º ğŸ”€ Provider Factory (configurable)
                                  â”‚         â”œâ”€â”€â–º AWS Bedrock (Haiku/Sonnet/Opus)
                                  â”‚         â””â”€â”€â–º OpenAI (gpt-4o-mini/gpt-4o)
                                  â”‚
                                  â”œâ”€â”€â–º Screening Agent (fast relevance check)
                                  â”œâ”€â”€â–º Analysis Agent (insight generation)
                                  â”œâ”€â”€â–º Copilot Agent (conversational assistant)
                                  â””â”€â”€â–º Summary Agent (structured reports)

ğŸŒ Chrome Extension (MV3) â”€â”€â–º tabCapture â”€â”€â–º MediaRecorder (5s chunks)
                                                    â”‚
                                                    â–¼
                                            â˜ï¸ FastAPI Backend
                                                    â”‚
                                      ffmpeg â”€â”€â–º faster-whisper â”€â”€â–º AI Pipeline
```

## Quick Start

### Backend
```bash
cd backend
uv sync
cp .env.example .env          # Configure environment
uv run pytest                 # Run tests (191 tests, 85% coverage)
uv run uvicorn meetmind.main:app --reload  # Start server
```

#### Choosing Your AI Provider (Zero Cost Strategy)
The backend supports the `LLMProvider` protocol, allowing you to use AWS Bedrock or **any OpenAI-compatible API** (Groq, Together, DeepSeek).

```bash
# Option A: Groq (Recommended for $0 Cost)
MEETMIND_LLM_PROVIDER=openai
MEETMIND_OPENAI_API_KEY=gsk_...
MEETMIND_OPENAI_BASE_URL=https://api.groq.com/openai/v1
MEETMIND_OPENAI_SCREENING_MODEL=llama-3.3-70b-versatile
MEETMIND_OPENAI_ANALYSIS_MODEL=llama-3.3-70b-versatile

# Option B: AWS Bedrock (Production/Enterprise)
MEETMIND_LLM_PROVIDER=bedrock
MEETMIND_AWS_REGION=us-east-1
```

### Flutter App
```bash
cd flutter_app
fvm use 3.38.3
fvm flutter pub get
fvm flutter test              # Run tests
fvm flutter run               # Run app
```

### Chrome Extension
```bash
# 1. Open chrome://extensions/
# 2. Enable Developer Mode
# 3. Load unpacked â†’ select chrome_extension/
# 4. Start backend, then click ğŸ§  MeetMind icon
```

### Quality Gates
```bash
./scripts/quality-check.sh    # 18/18 gates: Security, Lint, Format, Types, Tests, Coverage
```

## Project Structure

```
meetmind/
â”œâ”€â”€ flutter_app/              # ğŸ“± Flutter (Dart) â€” Mobile + Web
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ config/           # Theme, Router
â”‚   â”‚   â”œâ”€â”€ features/         # Features (Home, Meeting, History, Settings, Ask Aura)
â”‚   â”‚   â”œâ”€â”€ models/           # Domain models (Freezed-style)
â”‚   â”‚   â”œâ”€â”€ providers/        # Riverpod state management
â”‚   â”‚   â”œâ”€â”€ services/         # WebSocket, RevenueCat, Export, Audio
â”‚   â”‚   â””â”€â”€ native/           # dart:ffi whisper.cpp bridge
â”‚   â””â”€â”€ native/               # C++ plugin (whisper.cpp + CMake)
â”œâ”€â”€ backend/                  # â˜ï¸ FastAPI (Python 3.12) â€” Hexagonal Architecture
â”‚   â””â”€â”€ src/meetmind/
â”‚       â”œâ”€â”€ agents/           # AI agents (Screening, Analysis, Copilot)
â”‚       â”œâ”€â”€ providers/        # Factory: Bedrock, OpenAI-compatible, 4 STT engines
â”‚       â”œâ”€â”€ core/             # Domain logic (Transcript, Storage)
â”‚       â”œâ”€â”€ api/              # HTTP + WebSocket endpoints
â”‚       â”œâ”€â”€ config/           # Settings (Pydantic)
â”‚       â””â”€â”€ security/         # Input validation
â”œâ”€â”€ chrome_extension/         # ğŸŒ Chrome Extension (MV3)
â”‚   â”œâ”€â”€ popup/                # Control panel UI (dark theme)
â”‚   â”œâ”€â”€ offscreen/            # Audio recording (MediaRecorder)
â”‚   â””â”€â”€ service-worker.js     # Tab capture + message routing
â”œâ”€â”€ infra/                    # ğŸ—ï¸ Terraform (EC2 t3.small, Caddy, Docker)
â”œâ”€â”€ scripts/                  # ğŸ”§ quality-check.sh (18 gates)
â””â”€â”€ docs/                     # ğŸ“š Documentation (Business Plan, Vision, GTM)
```

## Tech Stack

| Component | Technology | Rationale |
|-----------|------------|-----------|
| Mobile/Web | **Flutter** (Dart) via FVM 3.38.3 | AOT native, `dart:ffi` â†’ C++ |
| STT on-device | **whisper.cpp** / **Moonshine** | CoreML/Metal, 99 languages |
| STT server | **Parakeet TDT 0.6B** / **Qwen3-ASR** | CPU int8, local processing (4 engines) |
| Backend | **FastAPI** (Python 3.12) | Hexagonal Architecture |
| AI Providers | **Groq** / **Bedrock** / **OpenAI** | Switchable via `LLMProvider` factory |
| Database | **PostgreSQL** + **pgvector** | Relational + Semantic Search (RAG) |
| State mgmt | **Riverpod** | Compile-safe DI |
| Extension | **Manifest V3** | `tabCapture` + Offscreen |

## Quality

| Metric | Value |
|--------|-------|
| Python tests | 191 passing |
| Coverage | 85% (â‰¥80% required) |
| Quality gates | 18/18 |
| MyPy | `--strict` mode, 0 errors |
| Ruff | 0 lint errors, 100% formatted |
| Security | gitleaks scan, no secrets |

## License

Private â€” Â© Cristian Reyes
